{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "#!pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo, list_available_datasets\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from data import Dataset\n",
    "\n",
    "myparams = {\n",
    "    'text.usetex': True,\n",
    "    'text.latex.preamble': r'\\usepackage{amsfonts}',\n",
    "    'font.family': 'Djvu Serif',\n",
    "    'font.size': 16,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.1,\n",
    "    'lines.linewidth': 2\n",
    "}\n",
    "plt.rcParams.update(myparams)\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    save_object,\n",
    "    load_object\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_regression = {\n",
    "    1: 'Abalone',\n",
    "    9: 'Auto MPG',\n",
    "    10: 'Automobile',\n",
    "    60: 'Liver Disorders',\n",
    "    87: 'Servo',\n",
    "    162: 'Forest Fires',\n",
    "    186: 'Wine Quality',\n",
    "    242: 'Energy Efficiency',\n",
    "    320: 'Student Performance',\n",
    "    368: 'Facebook Metrics',\n",
    "    477: 'Real Estate Valuation',\n",
    "    519: 'Heart Failure Clinical Records',\n",
    "    565: 'Bone marrow transplant: children',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[target])\n\u001b[1;32m     35\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target]\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m---> 37\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset(X, y)\n\u001b[1;32m     38\u001b[0m m, n \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     39\u001b[0m sample_sizes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, m, \u001b[38;5;241m21\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "results_regression = {}\n",
    "\n",
    "for key in tqdm(datasets_regression.keys()):\n",
    "    \n",
    "    # ==========================\n",
    "    data = fetch_ucirepo(id=key)\n",
    "    # ==========================\n",
    "    df = data.variables[['name', 'role', 'type']]\n",
    "    target = df[df.role == 'Target'].name.values[0]\n",
    "    columns = df[df.role == 'Feature'][['name', 'type']]\n",
    "    num_columns = columns.loc[(columns.type == 'Continuous') | (columns.type == 'Integer')].name.values\n",
    "    cat_columns = columns.loc[(columns.type == 'Categorical') | (columns.type == 'Binary')].name.values\n",
    "    columns = columns.name.values\n",
    "        \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), num_columns),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('linreg', LinearRegression())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df = data.data.original\n",
    "\n",
    "    if data.metadata.has_missing_values:\n",
    "        df = df.dropna(ignore_index=True)\n",
    "\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target].to_numpy().flatten()\n",
    "        \n",
    "    dataset = Dataset(X, y)\n",
    "    m, n = X.shape\n",
    "    sample_sizes = np.linspace(n+1, m, dtype=int)\n",
    "    B = 100\n",
    "\n",
    "    model = pipe\n",
    "    loss = mean_squared_error\n",
    "\n",
    "    means = []\n",
    "    variances = []\n",
    "\n",
    "    for k in sample_sizes:\n",
    "        tmp = []\n",
    "        for _ in range(B):\n",
    "            X_k, y_k = dataset.sample(k)\n",
    "            model.fit(X_k, y_k)\n",
    "            y_pred = model.predict(X)\n",
    "            tmp.append(loss(y, y_pred))\n",
    "        tmp = np.array(tmp)\n",
    "        means.append(tmp.mean())\n",
    "        variances.append(tmp.var())\n",
    "\n",
    "    means = np.array(means)\n",
    "    variances = np.array(variances)\n",
    "\n",
    "    results_regression[data.metadata.name] = {}\n",
    "    results_regression[data.metadata.name]['sample_sizes'] = sample_sizes\n",
    "    results_regression[data.metadata.name]['means'] = means\n",
    "    results_regression[data.metadata.name]['variances'] = variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(results_regression, \"plots/datasets_regression_new.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
